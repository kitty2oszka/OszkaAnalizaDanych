{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xl0c1eCTe3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "import plotly.express as px\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, classification_report, confusion_matrix,\n",
        "                           roc_auc_score, roc_curve, precision_recall_curve)\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvWIFxnAZOqq"
      },
      "outputs": [],
      "source": [
        "#pip install imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXI3IkJ7Qrq"
      },
      "source": [
        "1. Wczytywanie i podstawowe info o danych\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_TuoV21Jfr5"
      },
      "outputs": [],
      "source": [
        "hr: pd.DataFrame =  pd.read_csv(\"aug_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOqAbkE9KifF"
      },
      "outputs": [],
      "source": [
        "hr_test: pd.DataFrame =  pd.read_csv(\"aug_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDUbNP02jR26"
      },
      "outputs": [],
      "source": [
        "submission_sample: pd.DataFrame = pd.read_csv('sample_submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbQcj2VSKkfT"
      },
      "outputs": [],
      "source": [
        "hr_test.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKPrmbsNO-aj"
      },
      "outputs": [],
      "source": [
        "hr.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg9DFrm-6yDM"
      },
      "outputs": [],
      "source": [
        "print(f\"Rozmiar datasetu: {hr.shape}\")\n",
        "print(f\"\\nPodstawowe informacje:\\n\")\n",
        "print(hr.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWMpIfTSIA6x"
      },
      "source": [
        "Zmienne:\n",
        "\n",
        "\n",
        "enrollee_id : unikalne ID dla enroliego\n",
        "\n",
        "city: kod pocztowy\n",
        "\n",
        "citydevelopmentindex: Skala rozwoju miasta\n",
        "\n",
        "gender: Płec\n",
        "\n",
        "relevant_experience: istotne doświadczenie\n",
        "\n",
        "enrolled_university: rodzaj uniwerystetu\n",
        "\n",
        "education_level: stopień edukacji\n",
        "\n",
        "major_discipline : ukierunkowanie\n",
        "\n",
        "experience: doświadczenie w latach\n",
        "\n",
        "company_size: ilosc pracownikow w firmie w ktorej pracuje\n",
        "\n",
        "company_type : rodzaj zatrudnienia\n",
        "\n",
        "lastnewjob: roznica lat miedzy zatrudnieniami\n",
        "\n",
        "training_hours: ile godzin treningu\n",
        "\n",
        "target: 0 – nie szuka pracy, 1 – szuka pracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhkN3RVG7JnP"
      },
      "source": [
        "2. Eksploracyjna analiza danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fueIVxDa7Ng3"
      },
      "outputs": [],
      "source": [
        "print(f'Podstawowe statystyki train:\\n')\n",
        "print(hr.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUx5BziXUNqz"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nprocent udziału null w kolumnie:\")\n",
        "for col in hr.columns:\n",
        "    null_val = hr[col].isnull().sum()\n",
        "    null_prec = (null_val * 100) / hr.shape[0]\n",
        "    print(f'missing: {col}, ({null_prec:.1f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNPU0u6pTtAJ"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nRozkład zmiennej target:\")\n",
        "target_counts = hr['target'].value_counts()\n",
        "print(target_counts)\n",
        "print(f\"Proporcje: {target_counts / len(hr)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJdU3NDitNrR"
      },
      "source": [
        "Wizualizacje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQtwQu0gXQQ6"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Rozkład target\n",
        "axes[0,0].pie(target_counts.values, labels=['Nie szuka pracy (0)', 'Szuka pracy (1)'],\n",
        "       autopct='%1.1f%%', startangle=90)\n",
        "axes[0,0].set_title('Rozkład zmiennej target')\n",
        "\n",
        "# Rozkład wskaźnika rozwoju miasta\n",
        "axes[0,1].hist(hr['city_development_index'].dropna(), bins=20, alpha=0.7, color='skyblue')\n",
        "axes[0,1].set_title('Rozkład wskaźnika rozwoju miasta')\n",
        "axes[0,1].set_xlabel('City Development Index')\n",
        "\n",
        "# Godziny szkolenia vs Target\n",
        "hr.boxplot(column='training_hours', by='target', ax=axes[1,0])\n",
        "axes[1,0].set_title('Godziny szkolenia vs Target')\n",
        "axes[1,0].set_xlabel('Target')\n",
        "\n",
        "# Korelacja tylko dla zmiennych numerycznych\n",
        "numeric_cols = hr.select_dtypes(include=[np.number]).columns\n",
        "corr_matrix = hr[numeric_cols].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
        "axes[1,1].set_title('Macierz korelacji - zmienne numeryczne')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8sgrxIKeoDv"
      },
      "outputs": [],
      "source": [
        "categorical_cols = hr_processed.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = hr_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if 'target' in numerical_cols:\n",
        "    numerical_cols.remove('target')\n",
        "if 'enrollee_id' in numerical_cols:\n",
        "    numerical_cols.remove('enrollee_id')\n",
        "if 'enrollee_id' in categorical_cols:\n",
        "    categorical_cols.remove('enrollee_id')\n",
        "\n",
        "print(f\"Zmienne kategoryczne: {categorical_cols}\")\n",
        "print(f\"Zmienne numeryczne: {numerical_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1RFYGwddLuw"
      },
      "source": [
        "3. Oczyszczanie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX2L8pBzMZHE"
      },
      "source": [
        "Lista zmiennych porządkowych:\n",
        "\n",
        "education_level\n",
        "\n",
        "company_size\n",
        "\n",
        "experience\n",
        "\n",
        "last_new_job\n",
        "\n",
        "company_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSr2_17EriJ7"
      },
      "source": [
        "Mapowania dla kodowania zmiennych kategorycznych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfJX9UOlxsMq"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data, is_train=True):\n",
        "    data_processed = data.copy()\n",
        "\n",
        "    #mapowania dla kodowania zmiennych kategorycznych zainspirowane kodem z kaggle to rozwiązanie, mogę znaleźć link\n",
        "    mappings = {\n",
        "        'gender': {'Female': 2, 'Male': 1, 'Other': 0},\n",
        "        'relevent_experience': {'Has relevent experience': 1, 'No relevent experience': 0},\n",
        "        'enrolled_university': {'no_enrollment': 0, 'Full time course': 1, 'Part time course': 2},\n",
        "        'education_level': {'Primary School': 0, 'High School': 1, 'Graduate': 2, 'Masters': 3, 'Phd': 4},\n",
        "        'major_discipline': {'STEM': 0, 'Business Degree': 1, 'Arts': 2, 'Humanities': 3, 'No Major': 4, 'Other': 5},\n",
        "        'experience': {'<1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n",
        "                      '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17,\n",
        "                      '18': 18, '19': 19, '20': 20, '>20': 21},\n",
        "        'company_type': {'Pvt Ltd': 0, 'Funded Startup': 1, 'Early Stage Startup': 2, 'Other': 3, 'Public Sector': 4, 'NGO': 5},\n",
        "        'company_size': {'<10': 0, '10/49': 1, '50-99': 2, '100-500': 3, '500-999': 4, '1000-4999': 5, '5000-9999': 6, '10000+': 7},\n",
        "        'last_new_job': {'never': 0, '1': 1, '2': 2, '3': 3, '4': 4, '>4': 5}\n",
        "    }\n",
        "\n",
        "    #aplikacja mapowań\n",
        "    for col, mapping in mappings.items():\n",
        "        if col in data_processed.columns:\n",
        "            data_processed[col] = data_processed[col].map(mapping)\n",
        "            print(f\"Zakodowano zmienną: {col}\")\n",
        "\n",
        "    #wypełnienie brakujących wartości medianą\n",
        "    numeric_columns = data_processed.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_columns:\n",
        "        if col not in ['enrollee_id', 'target']:\n",
        "            median_val = data_processed[col].median()\n",
        "            data_processed[col].fillna(median_val, inplace=True)\n",
        "\n",
        "    #usunięcie duplikatów dla zbioru treningowego\n",
        "    if is_train:\n",
        "        duplicates = data_processed.duplicated().sum()\n",
        "        if duplicates > 0:\n",
        "            data_processed = data_processed.drop_duplicates()\n",
        "            print(f\"Usunięto {duplicates} duplikatów\")\n",
        "\n",
        "    return data_processed\n",
        "\n",
        "hr_processed = prepare_data(hr, is_train=True)\n",
        "hr_test_processed = prepare_data(hr_test, is_train=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xhz4hgXrnXP"
      },
      "source": [
        "4. Future Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtfs6GBvuVgx"
      },
      "outputs": [],
      "source": [
        "def prepare_features(data, target_col='target'):\n",
        "    \"\"\"Przygotowanie cech do modelowania\"\"\"\n",
        "    cols_to_drop = ['enrollee_id']\n",
        "    if target_col in data.columns:\n",
        "        cols_to_drop.append(target_col)\n",
        "\n",
        "    X = data.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    #wybieram tylko kolumny numeryczne\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    print(f\"Cechy wybrane do modelu:{list(X.columns)}\")\n",
        "    print(f\"Kształt macierzy cech:{X.shape}\")\n",
        "\n",
        "    return X\n",
        "\n",
        "X = prepare_features(hr_processed)\n",
        "y = hr_processed['target']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgW59gslupWa"
      },
      "outputs": [],
      "source": [
        "print(f\"Kształt target: {y.shape}\")\n",
        "print(f\"Rozkład target: {y.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZYfMBlDttK_"
      },
      "source": [
        "6. Podział danych na zbiory treningowy i testowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOnx4Ti6olJh"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Rozmiar zbioru treningowego: {X_train.shape}\")\n",
        "print(f\"Rozmiar zbioru walidacyjnego: {X_val.shape}\")\n",
        "print(f\"Proporcje w zbiorze treningowym: {y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Proporcje w zbiorze walidacyjnym: {y_val.value_counts(normalize=True)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emTQlHG3tVYc"
      },
      "source": [
        "5. Werfykacja założeń regresji liniowej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDkdWswz0sKT"
      },
      "outputs": [],
      "source": [
        "low_variance_cols = X.columns[X.var() < 0.01]\n",
        "if len(low_variance_cols) > 0:\n",
        "    print(f\"cechy o niskiej wariancji (< 0.01):{list(low_variance_cols)}\")\n",
        "else:\n",
        "    print(\"wszystkie cechy mają odpowiednią wariancję\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlVrK-J6tLc5"
      },
      "outputs": [],
      "source": [
        "X_with_const = sm.add_constant(X)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Cecha\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i+1)\n",
        "                   for i in range(len(X.columns))]\n",
        "\n",
        "print(\"Współczynniki VIF (Variance Inflation Factor):\")\n",
        "print(vif_data)\n",
        "print(\"\\nInterpretacja VIF:\")\n",
        "print(\"VIF < 5: Brak problemów z wielokolinearnością\")\n",
        "print(\"5 ≤ VIF < 10: Umiarkowana wielokolinearność\")\n",
        "print(\"VIF ≥ 10: Wysoka wielokolinearność\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH68NxQw36Gi"
      },
      "source": [
        "Najwyższy VIF 1.62, dużo poniżej progu, zmienne niezależne nie są silnie skorelowane ze sobą, więc model nie będzie miał problemu z niestabilnymi współczynnikami regresji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjaj3JH4wAaM"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
        "    print(f\"\\n{model_name} - WYNIKI:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1-score: {f1_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_pred_proba):.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred),\n",
        "        'recall': recall_score(y_true, y_pred),\n",
        "        'f1': f1_score(y_true, y_pred),\n",
        "        'auc_roc': roc_auc_score(y_true, y_pred_proba)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_fchB6Gf7Z7"
      },
      "outputs": [],
      "source": [
        "balancing_methods = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': None,\n",
        "    'SMOTEENN': None,\n",
        "    'UnderSampling': None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5E72P8pvwVV"
      },
      "source": [
        "Skalowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlYIAxZvvt_c"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBJ_1nISeKqC"
      },
      "source": [
        "SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDalHHeaeCK2"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "balancing_methods['SMOTE'] = (X_train_smote, y_train_smote)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmzN6SdfeQ5K"
      },
      "source": [
        "SMOTEEN (over i under sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SGPPSLTeS9m"
      },
      "outputs": [],
      "source": [
        "smoteenn = SMOTEENN(random_state=42)\n",
        "X_train_smoteenn, y_train_smoteenn = smoteenn.fit_resample(X_train, y_train)\n",
        "balancing_methods['SMOTEENN'] = (X_train_smoteenn, y_train_smoteenn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seKVO4LigBv7"
      },
      "source": [
        "random under sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1wZmo1Xf-2b"
      },
      "outputs": [],
      "source": [
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
        "balancing_methods['UnderSampling'] = (X_train_under, y_train_under)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjYgTUrIe9uP"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nRozkłady po wyważeniu:\")\n",
        "for method, (X_balanced, y_balanced) in balancing_methods.items():\n",
        "    print(f\"{method}: {Counter(y_balanced)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXWDEtf5jIiA"
      },
      "source": [
        "Najlepiej wypada SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E202IbfPtyRy"
      },
      "source": [
        "7. Budowanie modelu oraz jego Ewaluacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ghV0nkgvyYx"
      },
      "source": [
        "model regresji liniowej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFOApbEPv10Z"
      },
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPWRuqYD0f2Z"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmzm72oa0ciW"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "y_val_pred_proba_rf = rf_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "rf_scores = evaluate_model(y_val, y_val_pred_rf, y_val_pred_proba_rf, \"RANDOM FOREST\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vEAyehr0n1C"
      },
      "source": [
        "gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_AFUBQ10lAP"
      },
      "outputs": [],
      "source": [
        "gb_model = GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42)\n",
        "\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred_gb = gb_model.predict(X_val)\n",
        "y_val_pred_proba_gb = gb_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "gb_scores = evaluate_model(y_val, y_val_pred_gb, y_val_pred_proba_gb, \"GRADIENT BOOSTING\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZMoqJ_40uRG"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame({\n",
        "    'Logistic Regression': log_reg_scores,\n",
        "    'Random Forest': rf_scores,\n",
        "    'Gradient Boosting': gb_scores\n",
        "}).T\n",
        "\n",
        "print(results_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFIe-XE3iQOF"
      },
      "outputs": [],
      "source": [
        "best_model = results_df['f1'].idxmax()\n",
        "print(f\"\\nNajlepszy model: {best_model} (F1-score: {results_df.loc[best_model, 'f1']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp_S-N4T2FTJ"
      },
      "outputs": [],
      "source": [
        "gb_model_optimized = GradientBoostingClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGGQP67y2MXU"
      },
      "outputs": [],
      "source": [
        "gb_model_optimized.fit(X_train_smote, y_train_smote)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNS_llb2uMY2"
      },
      "outputs": [],
      "source": [
        "y_train_pred_log = log_reg.predict(X_train_scaled)\n",
        "y_val_pred_log = log_reg.predict(X_val_scaled)\n",
        "y_val_pred_proba_log = log_reg.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "log_reg_scores = evaluate_model(y_val, y_val_pred_log, y_val_pred_proba_log, \"REGRESJA LOGISTYCZNA\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb4dAsxo1Sfq"
      },
      "outputs": [],
      "source": [
        "y_val_pred_gb = gb_model.predict(X_val)\n",
        "y_val_pred_proba_gb = gb_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "gb_scores = evaluate_model(y_val, y_val_pred_gb, y_val_pred_proba_gb, \"GRADIENT BOOSTING\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fONciU-2QUC"
      },
      "outputs": [],
      "source": [
        "y_val_pred_gb_opt = gb_model_optimized.predict(X_val)\n",
        "y_val_pred_proba_gb_opt = gb_model_optimized.predict_proba(X_val)[:, 1]\n",
        "\n",
        "gb_opt_scores = evaluate_model(y_val, y_val_pred_gb_opt, y_val_pred_proba_gb_opt, \"GRADIENT BOOSTING OPTIMIZED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1-1a0Vh4EWa"
      },
      "source": [
        "Macierz pomyłek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36i8vP1blsSY"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    ('Logistic Regression', y_val_pred_log),\n",
        "    ('Random Forest', y_val_pred_rf),\n",
        "    ('Gradient Boosting', y_val_pred_gb),\n",
        "    ('Gradient Boosting opt', y_val_pred_gb_opt)\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, y_pred) in enumerate(models):\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
        "    axes[i].set_title(f'Confusion Matrix - {name}')\n",
        "    axes[i].set_xlabel('Predicted')\n",
        "    axes[i].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGh_PN9Q2gz1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tung1RBtieZ9"
      },
      "source": [
        "Krzywe ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVko2bmZiciH"
      },
      "outputs": [],
      "source": [
        "models_with_proba = [\n",
        "    ('Logistic Regression', y_val_pred_log, y_val_pred_proba_log),\n",
        "    ('Random Forest', y_val_pred_rf, y_val_pred_proba_rf),\n",
        "    ('Gradient Boosting', y_val_pred_gb, y_val_pred_proba_gb),\n",
        "    ('Gradient Boosting opt', y_val_pred_gb_opt, y_val_pred_proba_gb_opt)\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, y_pred, y_pred_proba in models_with_proba:\n",
        "    if y_pred_proba is not None and len(y_pred_proba) > 0:\n",
        "        fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
        "        auc_score = roc_auc_score(y_val, y_pred_proba)\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Krzywe ROC dla wszystkich modeli')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujd7YQzG5WUx"
      },
      "source": [
        "analiza najważniejszych cech regresji logistycznej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxMtBnYx5Aq_"
      },
      "outputs": [],
      "source": [
        "feature_importance_log = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'coefficient': log_reg.coef_[0]\n",
        "})\n",
        "feature_importance_log['abs_coefficient'] = np.abs(feature_importance_log['coefficient'])\n",
        "feature_importance_log = feature_importance_log.sort_values('abs_coefficient', ascending=False)\n",
        "print(feature_importance_log.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4DbzEAL5aLL"
      },
      "source": [
        "analiza najważniejszych cench gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39SoVhiv5Jff"
      },
      "outputs": [],
      "source": [
        "feature_importance_gb = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': gb_model.feature_importances_\n",
        "\n",
        "})\n",
        "feature_importance_gb = feature_importance_gb.sort_values('importance', ascending=False)\n",
        "print(feature_importance_gb.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dytgVBbI4Pcx"
      },
      "outputs": [],
      "source": [
        "feature_importance_gb_opt = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': gb_model_optimized.feature_importances_\n",
        "\n",
        "})\n",
        "feature_importance_gb_opt = feature_importance_gb_opt.sort_values('importance', ascending=False)\n",
        "print(feature_importance_gb_opt.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHAgSOY4ZjZ"
      },
      "source": [
        "walidacja krzyżowa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxNAlOfL4jxi",
        "outputId": "b5d7f61b-4742-4017-fbe7-642d78cdbdcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Opt - AUC CV: 0.7719 (+/- 0.0131)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Random Forest\n",
        "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "print(f\"Random Forest - AUC CV: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})\")\n",
        "\n",
        "# Gradient Boosting\n",
        "cv_scores_gb = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "print(f\"Gradient Boosting - AUC CV: {cv_scores_gb.mean():.4f} (+/- {cv_scores_gb.std() * 2:.4f})\")\n",
        "\n",
        "#Gradient Boosting Opt\n",
        "cv_scores_gb_opt = cross_val_score(gb_model_optimized, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "print(f\"Gradient Boosting Opt - AUC CV: {cv_scores_gb_opt.mean():.4f} (+/- {cv_scores_gb_opt.std() * 2:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vsVcNJI4sRo",
        "outputId": "c260784b-6c09-40e6-8a37-af5fad67547b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REGRESJA LOGISTYCZNA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.94      0.86      2877\n",
            "         1.0       0.58      0.25      0.35       955\n",
            "\n",
            "    accuracy                           0.77      3832\n",
            "   macro avg       0.69      0.59      0.60      3832\n",
            "weighted avg       0.74      0.77      0.73      3832\n",
            "\n",
            "\n",
            "RANDOM FOREST:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.89      0.86      2877\n",
            "         1.0       0.56      0.44      0.49       955\n",
            "\n",
            "    accuracy                           0.77      3832\n",
            "   macro avg       0.69      0.66      0.67      3832\n",
            "weighted avg       0.76      0.77      0.76      3832\n",
            "\n",
            "\n",
            "GRADIENT BOOSTING:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.89      0.86      2877\n",
            "         1.0       0.58      0.45      0.50       955\n",
            "\n",
            "    accuracy                           0.78      3832\n",
            "   macro avg       0.70      0.67      0.68      3832\n",
            "weighted avg       0.77      0.78      0.77      3832\n",
            "\n",
            "\n",
            "GRADIENT BOOSTING OPT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.88      0.86      2877\n",
            "         1.0       0.57      0.49      0.53       955\n",
            "\n",
            "    accuracy                           0.78      3832\n",
            "   macro avg       0.71      0.69      0.69      3832\n",
            "weighted avg       0.77      0.78      0.78      3832\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"REGRESJA LOGISTYCZNA:\")\n",
        "print(classification_report(y_val, y_val_pred_log))\n",
        "\n",
        "print(\"\\nRANDOM FOREST:\")\n",
        "print(classification_report(y_val, y_val_pred_rf))\n",
        "\n",
        "print(\"\\nGRADIENT BOOSTING:\")\n",
        "print(classification_report(y_val, y_val_pred_gb))\n",
        "\n",
        "print(\"\\nGRADIENT BOOSTING OPT:\")\n",
        "print(classification_report(y_val, y_val_pred_gb_opt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSZa9t8i5Hr",
        "outputId": "6720dcf4-bb05-4774-99b4-c3092d7158e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "KOŃCOWE PODSUMOWANIE\n",
            "Najlepszy model: Gradient Boosting\n",
            "Użyta metoda wyważenia: SMOTE\n",
            "Rozmiar danych treningowych po SMOTE: (23008, 11)\n",
            "Najważniejsze metryki najlepszego modelu:\n",
            "  Accuracy: 0.7805\n",
            "  Precision: 0.5774\n",
            "  Recall: 0.4450\n",
            "  F1: 0.5027\n",
            "  Auc_roc: 0.8005\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nKOŃCOWE PODSUMOWANIE\")\n",
        "print(f\"Najlepszy model: {best_model}\")\n",
        "print(f\"Użyta metoda wyważenia: SMOTE\")\n",
        "print(f\"Rozmiar danych treningowych po SMOTE: {X_train_smote.shape}\")\n",
        "print(f\"Najważniejsze metryki najlepszego modelu:\")\n",
        "for metric, value in results_df.loc[best_model].items():\n",
        "    print(f\"  {metric.capitalize()}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq-lqjPW5LD0"
      },
      "source": [
        "maksymalna czułość (recall) i f1-score klasy 1, to lepszy jest GB opt, jak mówiły wyniki metryk wcześniej.\n",
        "model o najwyższym AUC i stabilności (niska wariancja w CV), to zwykły GB jest również dobry i prostszy."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
